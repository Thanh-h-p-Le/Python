{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data & Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, the data we are working with is missing or is not in the most ideal format for us to work with, and it is up to us to modify it so that it fits our use case. In this notebook we will clean identified errors and explore the concept of imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Basic Packages & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue working with the student grades dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_ID</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>grade_avg</th>\n",
       "      <th>faculty</th>\n",
       "      <th>tuition</th>\n",
       "      <th>OH_participated</th>\n",
       "      <th>classes_skipped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20123456.0</td>\n",
       "      <td>John</td>\n",
       "      <td>Park</td>\n",
       "      <td>B</td>\n",
       "      <td>Arts</td>\n",
       "      <td>44191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20123457.0</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Great</td>\n",
       "      <td>B</td>\n",
       "      <td>Science</td>\n",
       "      <td>32245.0</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20123458.0</td>\n",
       "      <td>Sebastian</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>B</td>\n",
       "      <td>Business</td>\n",
       "      <td>42679.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20123459.0</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Bay</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>46478.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20123460.0</td>\n",
       "      <td>Scott</td>\n",
       "      <td>Foster</td>\n",
       "      <td>A</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>36784.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20123461.0</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Winehouse</td>\n",
       "      <td>B</td>\n",
       "      <td>Arts</td>\n",
       "      <td>36537.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20123462.0</td>\n",
       "      <td>Ralph</td>\n",
       "      <td>Wiggins</td>\n",
       "      <td>B</td>\n",
       "      <td>Business</td>\n",
       "      <td>40762.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20123463.0</td>\n",
       "      <td>Homer</td>\n",
       "      <td>Simpson</td>\n",
       "      <td>C</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>47669.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20123464.0</td>\n",
       "      <td>Marge</td>\n",
       "      <td>Simpson</td>\n",
       "      <td>B</td>\n",
       "      <td>Math</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"10\"</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20123465.0</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Gryffin</td>\n",
       "      <td>D</td>\n",
       "      <td>Arts</td>\n",
       "      <td>31956.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20123466.0</td>\n",
       "      <td>Louise</td>\n",
       "      <td>King</td>\n",
       "      <td>D</td>\n",
       "      <td>Business</td>\n",
       "      <td>33227.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20123467.0</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Botts</td>\n",
       "      <td>A</td>\n",
       "      <td>Science</td>\n",
       "      <td>34751.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20123468.0</td>\n",
       "      <td>Cyrus</td>\n",
       "      <td>Wong</td>\n",
       "      <td>A</td>\n",
       "      <td>Science</td>\n",
       "      <td>49298.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20123469.0</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>Chang</td>\n",
       "      <td>B</td>\n",
       "      <td>Business</td>\n",
       "      <td>35046.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20123470.0</td>\n",
       "      <td>Zachary</td>\n",
       "      <td>Chua</td>\n",
       "      <td>A</td>\n",
       "      <td>Business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20123471.0</td>\n",
       "      <td>Angus</td>\n",
       "      <td>Helmsworth</td>\n",
       "      <td>B</td>\n",
       "      <td>Business</td>\n",
       "      <td>47515.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20123472.0</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>McDowell</td>\n",
       "      <td>B</td>\n",
       "      <td>Business</td>\n",
       "      <td>43421.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20123473.0</td>\n",
       "      <td>Carol</td>\n",
       "      <td>Kuo</td>\n",
       "      <td>B</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>43063.0</td>\n",
       "      <td>\"7\"</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20123474.0</td>\n",
       "      <td>Tim</td>\n",
       "      <td>James</td>\n",
       "      <td>B</td>\n",
       "      <td>Science</td>\n",
       "      <td>46775.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20123475.0</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Curry</td>\n",
       "      <td>B</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20123476.0</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Reed</td>\n",
       "      <td>A</td>\n",
       "      <td>Business</td>\n",
       "      <td>41397.0</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20123477.0</td>\n",
       "      <td>Josh</td>\n",
       "      <td>Hart</td>\n",
       "      <td>A</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>46468.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20123478.0</td>\n",
       "      <td>Justin</td>\n",
       "      <td>Kang</td>\n",
       "      <td>A</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20123479.0</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>Yoo</td>\n",
       "      <td>A</td>\n",
       "      <td>Arts</td>\n",
       "      <td>41048.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20123480.0</td>\n",
       "      <td>Rosaline</td>\n",
       "      <td>Jun</td>\n",
       "      <td>A</td>\n",
       "      <td>Art$</td>\n",
       "      <td>44915.0</td>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20123481.0</td>\n",
       "      <td>Jimin</td>\n",
       "      <td>Park</td>\n",
       "      <td>B</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20123482.0</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>Kim</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>33376.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20123483.0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Dang</td>\n",
       "      <td>F</td>\n",
       "      <td>Business</td>\n",
       "      <td>44737.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20123484.0</td>\n",
       "      <td>Robbie</td>\n",
       "      <td>Tee</td>\n",
       "      <td>B</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>49682.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20123485.0</td>\n",
       "      <td>Shelly</td>\n",
       "      <td>Yoon</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>33585.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_ID first_name   last_name grade_avg      faculty  tuition  \\\n",
       "0   20123456.0       John        Park         B         Arts  44191.0   \n",
       "1   20123457.0       Alex       Great         B      Science  32245.0   \n",
       "2   20123458.0  Sebastian      Taylor         B     Business  42679.0   \n",
       "3   20123459.0    Michael         Bay         A         Math  46478.0   \n",
       "4   20123460.0      Scott      Foster         A  Engineering  36784.0   \n",
       "5   20123461.0        Amy   Winehouse         B         Arts  36537.0   \n",
       "6   20123462.0      Ralph     Wiggins         B     Business  40762.0   \n",
       "7   20123463.0      Homer     Simpson         C  Engineering  47669.0   \n",
       "8   20123464.0      Marge     Simpson         B         Math      NaN   \n",
       "9   20123465.0      Peter     Gryffin         D         Arts  31956.0   \n",
       "10  20123466.0     Louise        King         D     Business  33227.0   \n",
       "11  20123467.0      Megan       Botts         A      Science  34751.0   \n",
       "12  20123468.0      Cyrus        Wong         A      Science  49298.0   \n",
       "13  20123469.0   Michelle       Chang         B     Business  35046.0   \n",
       "14  20123470.0    Zachary        Chua         A     Business      NaN   \n",
       "15  20123471.0      Angus  Helmsworth         B     Business  47515.0   \n",
       "16  20123472.0      Aaron    McDowell         B     Business  43421.0   \n",
       "17  20123473.0      Carol         Kuo         B  Engineering  43063.0   \n",
       "18  20123474.0        Tim       James         B      Science  46775.0   \n",
       "19  20123475.0    Johnson       Curry         B  Engineering  45000.0   \n",
       "20  20123476.0       Paul        Reed         A     Business  41397.0   \n",
       "21  20123477.0       Josh        Hart         A  Engineering  46468.0   \n",
       "22  20123478.0     Justin        Kang         A  Engineering      NaN   \n",
       "23  20123479.0      Kevin         Yoo         A         Arts  41048.0   \n",
       "24  20123480.0   Rosaline         Jun         A         Art$  44915.0   \n",
       "25  20123481.0      Jimin        Park         B  Engineering     40.0   \n",
       "26  20123482.0     Joseph         Kim         A         Math  33376.0   \n",
       "27  20123483.0      Chris        Dang         F     Business  44737.0   \n",
       "28  20123484.0     Robbie         Tee         B  Engineering  49682.0   \n",
       "29  20123485.0     Shelly        Yoon         A         Math  33585.0   \n",
       "30         NaN     Joseph         NaN         A      English      NaN   \n",
       "\n",
       "   OH_participated  classes_skipped  \n",
       "0                0              5.0  \n",
       "1              \"4\"             10.0  \n",
       "2                6              7.0  \n",
       "3               15              2.0  \n",
       "4                5              8.0  \n",
       "5               10              3.0  \n",
       "6                2              8.0  \n",
       "7                4              7.0  \n",
       "8             \"10\"              3.0  \n",
       "9                7              7.0  \n",
       "10               6              7.0  \n",
       "11              25              1.0  \n",
       "12              20              0.0  \n",
       "13               5              4.0  \n",
       "14              10              0.0  \n",
       "15              10              1.0  \n",
       "16             NaN              2.0  \n",
       "17             \"7\"              4.0  \n",
       "18               9              4.0  \n",
       "19               9              3.0  \n",
       "20              14              NaN  \n",
       "21               4              8.0  \n",
       "22               2              9.0  \n",
       "23               8              1.0  \n",
       "24              25              3.0  \n",
       "25              20              NaN  \n",
       "26              12              6.0  \n",
       "27             NaN              8.0  \n",
       "28              10              6.0  \n",
       "29               5             10.0  \n",
       "30               2              4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data to a pandas dataframe\n",
    "df_grades = pd.read_csv('student grades.csv')\n",
    "df_grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with identified errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lesson, we discovered various errors and will now explore ways to deal with them.\n",
    "\n",
    "Lets first look at the number of null values in our dataset, both in the column level and row level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_ID         1\n",
       "first_name         0\n",
       "last_name          1\n",
       "grade_avg          0\n",
       "faculty            0\n",
       "tuition            4\n",
       "OH_participated    2\n",
       "classes_skipped    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify missing values (NULLS) in the dataset\n",
    "df_grades.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_ID</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>grade_avg</th>\n",
       "      <th>faculty</th>\n",
       "      <th>tuition</th>\n",
       "      <th>OH_participated</th>\n",
       "      <th>classes_skipped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20123482.0</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>Kim</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>33376.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20123483.0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Dang</td>\n",
       "      <td>F</td>\n",
       "      <td>Business</td>\n",
       "      <td>44737.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20123484.0</td>\n",
       "      <td>Robbie</td>\n",
       "      <td>Tee</td>\n",
       "      <td>B</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>49682.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20123485.0</td>\n",
       "      <td>Shelly</td>\n",
       "      <td>Yoon</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>33585.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_ID first_name last_name grade_avg      faculty  tuition  \\\n",
       "26  20123482.0     Joseph       Kim         A         Math  33376.0   \n",
       "27  20123483.0      Chris      Dang         F     Business  44737.0   \n",
       "28  20123484.0     Robbie       Tee         B  Engineering  49682.0   \n",
       "29  20123485.0     Shelly      Yoon         A         Math  33585.0   \n",
       "30         NaN     Joseph       NaN         A      English      NaN   \n",
       "\n",
       "   OH_participated  classes_skipped  \n",
       "26              12              6.0  \n",
       "27             NaN              8.0  \n",
       "28              10              6.0  \n",
       "29               5             10.0  \n",
       "30               2              4.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grades.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simpliest way of getting rid of null values is to use the `drop_na` function. This allows us to either drop all rows that have null values or all columns that have null values. We can confirm that the rows or columns were dropped by looking at the shape of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop all rows or columns with nas (not recommended)\n",
    "df_drop_na = df_grades.dropna()      #Use axis = 1 to drop columns with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw in our previous notebook that the last row of our column was identified as a row with lots of errors that we can safely decide to drop.\n",
    "\n",
    "To easily drop only the last row of our dataset which contains the errors, we can simply use the `drop` function and use the index of the `tail` function in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_ID</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>grade_avg</th>\n",
       "      <th>faculty</th>\n",
       "      <th>tuition</th>\n",
       "      <th>OH_participated</th>\n",
       "      <th>classes_skipped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20123481.0</td>\n",
       "      <td>Jimin</td>\n",
       "      <td>Park</td>\n",
       "      <td>B</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20123482.0</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>Kim</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>33376.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20123483.0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Dang</td>\n",
       "      <td>F</td>\n",
       "      <td>Business</td>\n",
       "      <td>44737.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20123484.0</td>\n",
       "      <td>Robbie</td>\n",
       "      <td>Tee</td>\n",
       "      <td>B</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>49682.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20123485.0</td>\n",
       "      <td>Shelly</td>\n",
       "      <td>Yoon</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>33585.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_ID first_name last_name grade_avg      faculty  tuition  \\\n",
       "25  20123481.0      Jimin      Park         B  Engineering     40.0   \n",
       "26  20123482.0     Joseph       Kim         A         Math  33376.0   \n",
       "27  20123483.0      Chris      Dang         F     Business  44737.0   \n",
       "28  20123484.0     Robbie       Tee         B  Engineering  49682.0   \n",
       "29  20123485.0     Shelly      Yoon         A         Math  33585.0   \n",
       "\n",
       "   OH_participated  classes_skipped  \n",
       "25              20              NaN  \n",
       "26              12              6.0  \n",
       "27             NaN              8.0  \n",
       "28              10              6.0  \n",
       "29               5             10.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping last row with the tail function\n",
    "\n",
    "df_grades = df_grades.drop(df_grades.tail(1).index)\n",
    "df_grades.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the dropped last row, we can safely assume that that specific row of data was an error, because there was no name associated with it and there were many missing data.\n",
    "\n",
    "However, in most instances we want to keep our data and leave it as a last resort to drop it. We will explore other methods of cleaning our data using imputation further down in the notebook. \n",
    "\n",
    "We saw before that there was a typo in one of the faculty values by looking at the `value_counts` function. To solve this, we can use the `replace` function to replace the typo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faculty\n",
       "Business       9\n",
       "Engineering    8\n",
       "Arts           4\n",
       "Science        4\n",
       "Math           4\n",
       "Art$           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore what unique values appear in the Faculty column\n",
    "df_grades['faculty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faculty\n",
       "Business       9\n",
       "Engineering    8\n",
       "Arts           5\n",
       "Science        4\n",
       "Math           4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there any categorical values which acutally have been entered incorrectly? Make them consistent with replace.\n",
    "df_grades['faculty'] = df_grades['faculty'].str.replace('$', 's')\n",
    "df_grades['faculty'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we discovered using the `describe` function, we were able to see that there was a minimum tuition value that didn't make sense since the minimum tuition was 40 dollars. Luckily, we were able to find out from the external data source that their tuition was actually 40000 dollars. We can fix this by correcting the student's tuition value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_ID</th>\n",
       "      <th>tuition</th>\n",
       "      <th>classes_skipped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.012347e+07</td>\n",
       "      <td>39727.592593</td>\n",
       "      <td>4.892857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.803408e+00</td>\n",
       "      <td>9749.186961</td>\n",
       "      <td>3.071244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.012346e+07</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.012346e+07</td>\n",
       "      <td>34898.500000</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.012347e+07</td>\n",
       "      <td>42679.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.012348e+07</td>\n",
       "      <td>45734.000000</td>\n",
       "      <td>7.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.012348e+07</td>\n",
       "      <td>49682.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         student_ID       tuition  classes_skipped\n",
       "count  3.000000e+01     27.000000        28.000000\n",
       "mean   2.012347e+07  39727.592593         4.892857\n",
       "std    8.803408e+00   9749.186961         3.071244\n",
       "min    2.012346e+07     40.000000         0.000000\n",
       "25%    2.012346e+07  34898.500000         2.750000\n",
       "50%    2.012347e+07  42679.000000         4.500000\n",
       "75%    2.012348e+07  45734.000000         7.250000\n",
       "max    2.012348e+07  49682.000000        10.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore what range of values exist for numerical columns\n",
    "df_grades.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_ID</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>grade_avg</th>\n",
       "      <th>faculty</th>\n",
       "      <th>tuition</th>\n",
       "      <th>OH_participated</th>\n",
       "      <th>classes_skipped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20123481.0</td>\n",
       "      <td>Jimin</td>\n",
       "      <td>Park</td>\n",
       "      <td>B</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_ID first_name last_name grade_avg      faculty  tuition  \\\n",
       "25  20123481.0      Jimin      Park         B  Engineering     40.0   \n",
       "\n",
       "   OH_participated  classes_skipped  \n",
       "25              20              NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identifying which index is the student's\n",
    "df_grades[df_grades['tuition'] == 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_ID</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>grade_avg</th>\n",
       "      <th>faculty</th>\n",
       "      <th>tuition</th>\n",
       "      <th>OH_participated</th>\n",
       "      <th>classes_skipped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20123481.0</td>\n",
       "      <td>Jimin</td>\n",
       "      <td>Park</td>\n",
       "      <td>B</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_ID first_name last_name grade_avg      faculty  tuition  \\\n",
       "25  20123481.0      Jimin      Park         B  Engineering  40000.0   \n",
       "\n",
       "   OH_participated  classes_skipped  \n",
       "25              20              NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the index in the tuition column to equal 40,000\n",
    "df_grades['tuition'][25] = 40000\n",
    "df_grades.iloc[[25]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Errors for Data Types\n",
    "\n",
    "When importing data, there may be some data in places that there shouldn't be, whether it is in a different format or data that doesn't belong. For example, you may have noticed when we first imported the dataset that the \"OfficeHoursParticipated\" column had quotation marks to some numbers. Because of this, when we use the `info` function, the data type is shown as an object rather than a float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   student_ID       30 non-null     float64\n",
      " 1   first_name       30 non-null     object \n",
      " 2   last_name        30 non-null     object \n",
      " 3   grade_avg        30 non-null     object \n",
      " 4   faculty          30 non-null     object \n",
      " 5   tuition          27 non-null     float64\n",
      " 6   OH_participated  28 non-null     object \n",
      " 7   classes_skipped  28 non-null     float64\n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Explore what errors exist in the data\n",
    "df_grades.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this error, we can use the `str.replace` function to extract the quotation marks and convert the entire column into the approrpriate data type. In this case, it would be the float data type for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the str.replace function to extract the quotation mark\n",
    "df_grades['OH_participated'] = df_grades['OH_participated'].str.replace('\"','').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   student_ID       30 non-null     float64\n",
      " 1   first_name       30 non-null     object \n",
      " 2   last_name        30 non-null     object \n",
      " 3   grade_avg        30 non-null     object \n",
      " 4   faculty          30 non-null     object \n",
      " 5   tuition          27 non-null     float64\n",
      " 6   OH_participated  28 non-null     float64\n",
      " 7   classes_skipped  28 non-null     float64\n",
      "dtypes: float64(4), object(4)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_grades.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a basic level, we can replace missing values or errors with any value we wish. But we should think carefully about if the values that we are replacing make sense. For example, a common way of filling in values is to fill in the column using the average of the column distribution. However, in most cases, these averages can really vary depending on other factors, and it may not be the best method to fill in your data.\n",
    "\n",
    "Lets explore ways to fill in our columns better. We will start by identifying the null values in our columns in our dataframe using the `isna` and `sum` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_ID         0\n",
       "first_name         0\n",
       "last_name          0\n",
       "grade_avg          0\n",
       "faculty            0\n",
       "tuition            3\n",
       "OH_participated    2\n",
       "classes_skipped    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the count of null values to identify easily which columns contain null values\n",
    "df_grades.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that three columns have a null count greater than 0.\n",
    "\n",
    "Some null values can be treated as zeros, whilst some may really be missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have confirmed with staff that OHparticipated and ClassesSkipped both appear as null when these values are zero. The team know the data well enough to verify this. Therefore we can fill the nulls with zeros using the fillna() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Replace OH_participated & Classes_skipped nulls with zeros\n",
    "df_grades['OH_participated'] = df_grades['OH_participated'].fillna(0)\n",
    "df_grades['classes_skipped'] = df_grades['classes_skipped'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at the last column, \"ClassesSkipped\". We can make the same inference as the previous column by stating that null values mean no classes were skipped. However, lets assume that it is guaranteed that all students skipped classes. To be as accurate as possible, we can try to fill the NA values with the median value of all the classes skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_ID         0\n",
       "first_name         0\n",
       "last_name          0\n",
       "grade_avg          0\n",
       "faculty            0\n",
       "tuition            3\n",
       "OH_participated    0\n",
       "classes_skipped    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace ClassesSkipped nulls with zeros\n",
    "df_grades.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Lets now finally look at the null values in the \"Tuition\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_ID</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>grade_avg</th>\n",
       "      <th>faculty</th>\n",
       "      <th>tuition</th>\n",
       "      <th>OH_participated</th>\n",
       "      <th>classes_skipped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20123464.0</td>\n",
       "      <td>Marge</td>\n",
       "      <td>Simpson</td>\n",
       "      <td>B</td>\n",
       "      <td>Math</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20123470.0</td>\n",
       "      <td>Zachary</td>\n",
       "      <td>Chua</td>\n",
       "      <td>A</td>\n",
       "      <td>Business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20123478.0</td>\n",
       "      <td>Justin</td>\n",
       "      <td>Kang</td>\n",
       "      <td>A</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_ID first_name last_name grade_avg      faculty  tuition  \\\n",
       "8   20123464.0      Marge   Simpson         B         Math      NaN   \n",
       "14  20123470.0    Zachary      Chua         A     Business      NaN   \n",
       "22  20123478.0     Justin      Kang         A  Engineering      NaN   \n",
       "\n",
       "    OH_participated  classes_skipped  \n",
       "8              10.0              3.0  \n",
       "14             10.0              0.0  \n",
       "22              2.0              9.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the null values in \"Tuition\" column\n",
    "df_grades[df_grades['tuition'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this instance, we cannot use zeros to fill in the values, since it wouldn't make sense for students to not pay any tuition. One approriate approach to filling in these values is to take the average of the tuition of each faculty. That way, the average can be tied to each faculty since each faculty may have different tuition rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert JohnAmyPeterKevinRosaline to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[0;32m   1493\u001b[0m         how,\n\u001b[0;32m   1494\u001b[0m         axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1495\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[1;32m--> 959\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[0;32m    960\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[0;32m    961\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    962\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    963\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    964\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[0;32m    650\u001b[0m         values,\n\u001b[0;32m    651\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    655\u001b[0m     )\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_op_ndim_compat(\n\u001b[0;32m    658\u001b[0m     values,\n\u001b[0;32m    659\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    660\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    661\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    662\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    664\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:497\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m--> 497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_cython_op(\n\u001b[0;32m    498\u001b[0m     values,\n\u001b[0;32m    499\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    500\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    501\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    502\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    503\u001b[0m     result_mask\u001b[38;5;241m=\u001b[39mresult_mask,\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    505\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[1;32m--> 541\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow, values\u001b[38;5;241m.\u001b[39mdtype, is_numeric)\n\u001b[0;32m    542\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[1;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39m__signatures__:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction is not implemented for this dtype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1692\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(x)\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'JohnAmyPeterKevinRosaline'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1696\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Find tuition averages (returned as series)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fac_avg \u001b[38;5;241m=\u001b[39m df_grades\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaculty\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtuition\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m fac_avg\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Assigning varaibles based on the faculty average\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1507\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1508\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1509\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1503\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1503\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[0;32m   1504\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m-> 1503\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     ser \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;66;03m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;66;03m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;66;03m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[1;32m-> 1457\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, Categorical):\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;66;03m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;66;03m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m     \u001b[38;5;66;03m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m_from_sequence(res_values, dtype\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    996\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1012\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m   1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1857\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11539\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11540\u001b[0m     _num_doc,\n\u001b[0;32m  11541\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11554\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11555\u001b[0m ):\n\u001b[1;32m> 11556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11196\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11203\u001b[0m     )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11159\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11160\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\series.py:4670\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   4666\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4668\u001b[0m     )\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 421\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    424\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    724\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    726\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 727\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum))\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    730\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1696\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m             \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n\u001b[1;32m-> 1699\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert JohnAmyPeterKevinRosaline to numeric"
     ]
    }
   ],
   "source": [
    "# Find tuition averages (returned as series)\n",
    "fac_avg = df_grades.groupby('faculty').mean()['tuition']\n",
    "fac_avg\n",
    "\n",
    "# Assigning varaibles based on the faculty average\n",
    "df_grades['tuition'] = np.where(np.isnan(df_grades['tuition']), fac_avg.loc[df_grades['faculty']],df_grades['tuition'])\n",
    "\n",
    "df_grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can now check using the info function if there are any null values remaining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_ID         0\n",
       "first_name         0\n",
       "last_name          0\n",
       "grade_avg          0\n",
       "faculty            0\n",
       "tuition            3\n",
       "OH_participated    0\n",
       "classes_skipped    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grades.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Removing Unwanted String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we are working with the phone dataset. However, as you know we identified a few problems.\n",
    "\n",
    "Task:\n",
    "- Explore the unique values in the marketplace column, identify the typos, and fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year_made</th>\n",
       "      <th>name</th>\n",
       "      <th>battery_life_percentage</th>\n",
       "      <th>storage</th>\n",
       "      <th>magnet_charging</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>years_owned</th>\n",
       "      <th>visible_scratches</th>\n",
       "      <th>pro</th>\n",
       "      <th>original_sale_price</th>\n",
       "      <th>#_of_previous_owners</th>\n",
       "      <th>megapixel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>551.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>iPhone_11</td>\n",
       "      <td>74</td>\n",
       "      <td>64</td>\n",
       "      <td>no</td>\n",
       "      <td>kijiji</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>no</td>\n",
       "      <td>747</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>822.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>iPhone_12</td>\n",
       "      <td>94</td>\n",
       "      <td>128</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1008.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>iPhone_14</td>\n",
       "      <td>97</td>\n",
       "      <td>256</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist!</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>iPhone_13</td>\n",
       "      <td>90</td>\n",
       "      <td>128</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>839.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>iPhone_12</td>\n",
       "      <td>91</td>\n",
       "      <td>256</td>\n",
       "      <td>yes</td>\n",
       "      <td>kijiji</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>969</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1326.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>iPhone_14</td>\n",
       "      <td>91</td>\n",
       "      <td>64</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>1394</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>458.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>iPhone_11</td>\n",
       "      <td>75</td>\n",
       "      <td>256</td>\n",
       "      <td>no</td>\n",
       "      <td>facebook</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>702</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>487.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>iPhone_11</td>\n",
       "      <td>87</td>\n",
       "      <td>256</td>\n",
       "      <td>no</td>\n",
       "      <td>facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>no</td>\n",
       "      <td>781</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1340.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>iPhone_14</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>1411</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1144.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>iPhone_13</td>\n",
       "      <td>94</td>\n",
       "      <td>128</td>\n",
       "      <td>yes</td>\n",
       "      <td>facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>1249</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  year_made       name  battery_life_percentage  storage  \\\n",
       "0     551.0       2019  iPhone_11                       74       64   \n",
       "1     822.0       2020  iPhone_12                       94      128   \n",
       "2    1008.0       2022  iPhone_14                       97      256   \n",
       "3       NaN       2021  iPhone_13                       90      128   \n",
       "4     839.0       2020  iPhone_12                       91      256   \n",
       "..      ...        ...        ...                      ...      ...   \n",
       "344  1326.0       2022  iPhone_14                       91       64   \n",
       "345   458.0       2019  iPhone_11                       75      256   \n",
       "346   487.0       2019  iPhone_11                       87      256   \n",
       "347  1340.0       2022  iPhone_14                      100      256   \n",
       "348  1144.0       2021  iPhone_13                       94      128   \n",
       "\n",
       "    magnet_charging  marketplace  years_owned  visible_scratches  pro  \\\n",
       "0                no       kijiji            2                  9   no   \n",
       "1               yes   craigslist            2                  6   no   \n",
       "2               yes  craigslist!            0                  2   no   \n",
       "3               yes   craigslist            2                  2   no   \n",
       "4               yes       kijiji            1                  5   no   \n",
       "..              ...          ...          ...                ...  ...   \n",
       "344             yes   craigslist            0                  0   no   \n",
       "345              no     facebook            3                  3   no   \n",
       "346              no     facebook            1                  7   no   \n",
       "347             yes   craigslist            0                  0   no   \n",
       "348             yes     facebook            1                  1  yes   \n",
       "\n",
       "     original_sale_price  #_of_previous_owners  megapixel  \n",
       "0                    747                     1         12  \n",
       "1                    888                     1         16  \n",
       "2                   1185                     1         22  \n",
       "3                    887                     1         20  \n",
       "4                    969                     1         16  \n",
       "..                   ...                   ...        ...  \n",
       "344                 1394                     1         22  \n",
       "345                  702                     2         12  \n",
       "346                  781                     2         12  \n",
       "347                 1411                     1         22  \n",
       "348                 1249                     1         20  \n",
       "\n",
       "[349 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data to a pandas dataframe\n",
    "df_phone = pd.read_csv('phone_marketplace_dataset_cleaning_set.csv')\n",
    "df_phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace\n",
       "facebook       125\n",
       "craigslist     110\n",
       "kijiji         106\n",
       "craigslist!      3\n",
       "facebook!        3\n",
       "kijiji!          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the unique values in the marketplace column\n",
    "df_phone['marketplace'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          kijiji\n",
       "1      craigslist\n",
       "2      craigslist\n",
       "3      craigslist\n",
       "4          kijiji\n",
       "          ...    \n",
       "344    craigslist\n",
       "345      facebook\n",
       "346      facebook\n",
       "347    craigslist\n",
       "348      facebook\n",
       "Name: marketplace, Length: 349, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the WRONG way to replace values in a dataframe\n",
    "df_phone['marketplace'].str.replace('!','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace\n",
       "facebook      128\n",
       "craigslist    113\n",
       "kijiji        108\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace or remove all ! in the marketplace column\n",
    "df_phone['marketplace'] = df_phone['marketplace'].str.replace('!','')\n",
    "df_phone['marketplace'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Imputing Nulls with Appropriate Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the column that has null values and populate the values using a basic imputation method of your choice.\n",
    "\n",
    "Task:\n",
    "- Identify the columns that need to be dealt with\n",
    "- Populate missing values with a basic imputation method of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price                      6\n",
       "year_made                  0\n",
       "name                       0\n",
       "battery_life_percentage    0\n",
       "storage                    0\n",
       "magnet_charging            0\n",
       "marketplace                0\n",
       "years_owned                0\n",
       "visible_scratches          0\n",
       "pro                        0\n",
       "original_sale_price        0\n",
       "#_of_previous_owners       0\n",
       "megapixel                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phone.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year_made</th>\n",
       "      <th>name</th>\n",
       "      <th>battery_life_percentage</th>\n",
       "      <th>storage</th>\n",
       "      <th>magnet_charging</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>years_owned</th>\n",
       "      <th>visible_scratches</th>\n",
       "      <th>pro</th>\n",
       "      <th>original_sale_price</th>\n",
       "      <th>#_of_previous_owners</th>\n",
       "      <th>megapixel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>iPhone_13</td>\n",
       "      <td>90</td>\n",
       "      <td>128</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>iPhone_11</td>\n",
       "      <td>87</td>\n",
       "      <td>128</td>\n",
       "      <td>no</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>738</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>iPhone_14</td>\n",
       "      <td>94</td>\n",
       "      <td>256</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1403</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>iPhone_13</td>\n",
       "      <td>90</td>\n",
       "      <td>64</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>iPhone_12</td>\n",
       "      <td>83</td>\n",
       "      <td>64</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>894</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>iPhone_14</td>\n",
       "      <td>99</td>\n",
       "      <td>64</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1491</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price  year_made       name  battery_life_percentage  storage  \\\n",
       "3      NaN       2021  iPhone_13                       90      128   \n",
       "17     NaN       2019  iPhone_11                       87      128   \n",
       "92     NaN       2022  iPhone_14                       94      256   \n",
       "227    NaN       2021  iPhone_13                       90       64   \n",
       "254    NaN       2020  iPhone_12                       83       64   \n",
       "343    NaN       2022  iPhone_14                       99       64   \n",
       "\n",
       "    magnet_charging marketplace  years_owned  visible_scratches  pro  \\\n",
       "3               yes  craigslist            2                  2   no   \n",
       "17               no  craigslist            4                  1   no   \n",
       "92              yes  craigslist            0                  1   no   \n",
       "227             yes  craigslist            2                  2   no   \n",
       "254             yes  craigslist            1                  0  yes   \n",
       "343             yes  craigslist            0                  0  yes   \n",
       "\n",
       "     original_sale_price  #_of_previous_owners  megapixel  \n",
       "3                    887                     1         20  \n",
       "17                   738                     4         12  \n",
       "92                  1403                     1         22  \n",
       "227                 1021                     1         20  \n",
       "254                  894                     1         16  \n",
       "343                 1491                     1         22  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the rows that are null\n",
    "df_phone[df_phone['price'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert nonononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononono to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[0;32m   1493\u001b[0m         how,\n\u001b[0;32m   1494\u001b[0m         axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1495\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[1;32m--> 959\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[0;32m    960\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[0;32m    961\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    962\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    963\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    964\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[0;32m    650\u001b[0m         values,\n\u001b[0;32m    651\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    655\u001b[0m     )\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_op_ndim_compat(\n\u001b[0;32m    658\u001b[0m     values,\n\u001b[0;32m    659\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    660\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    661\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    662\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    664\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:497\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m--> 497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_cython_op(\n\u001b[0;32m    498\u001b[0m     values,\n\u001b[0;32m    499\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    500\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    501\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    502\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    503\u001b[0m     result_mask\u001b[38;5;241m=\u001b[39mresult_mask,\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    505\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[1;32m--> 541\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow, values\u001b[38;5;241m.\u001b[39mdtype, is_numeric)\n\u001b[0;32m    542\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[1;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39m__signatures__:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction is not implemented for this dtype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1692\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(x)\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'nonononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononono'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1696\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Find phone price averages (returned as series)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m phone_avg \u001b[38;5;241m=\u001b[39m df_phone\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m phone_avg\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1507\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1508\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1509\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1503\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1503\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[0;32m   1504\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m-> 1503\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     ser \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;66;03m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;66;03m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;66;03m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[1;32m-> 1457\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, Categorical):\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;66;03m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;66;03m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m     \u001b[38;5;66;03m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m_from_sequence(res_values, dtype\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    996\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1012\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m   1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1857\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11539\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11540\u001b[0m     _num_doc,\n\u001b[0;32m  11541\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11554\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11555\u001b[0m ):\n\u001b[1;32m> 11556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11196\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11203\u001b[0m     )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11159\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11160\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\series.py:4670\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   4666\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4668\u001b[0m     )\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 421\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    424\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    724\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    726\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 727\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum))\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    730\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1696\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m             \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n\u001b[1;32m-> 1699\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert nonononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononononono to numeric"
     ]
    }
   ],
   "source": [
    "#Find phone price averages (returned as series)\n",
    "phone_avg = df_phone.groupby('name').mean()['price']\n",
    "phone_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year_made</th>\n",
       "      <th>name</th>\n",
       "      <th>battery_life_percentage</th>\n",
       "      <th>storage</th>\n",
       "      <th>magnet_charging</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>years_owned</th>\n",
       "      <th>visible_scratches</th>\n",
       "      <th>pro</th>\n",
       "      <th>original_sale_price</th>\n",
       "      <th>#_of_previous_owners</th>\n",
       "      <th>megapixel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>551.000000</td>\n",
       "      <td>2019</td>\n",
       "      <td>iPhone_11</td>\n",
       "      <td>74</td>\n",
       "      <td>64</td>\n",
       "      <td>no</td>\n",
       "      <td>kijiji</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>no</td>\n",
       "      <td>747</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>822.000000</td>\n",
       "      <td>2020</td>\n",
       "      <td>iPhone_12</td>\n",
       "      <td>94</td>\n",
       "      <td>128</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1008.000000</td>\n",
       "      <td>2022</td>\n",
       "      <td>iPhone_14</td>\n",
       "      <td>97</td>\n",
       "      <td>256</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013.164557</td>\n",
       "      <td>2021</td>\n",
       "      <td>iPhone_13</td>\n",
       "      <td>90</td>\n",
       "      <td>128</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>839.000000</td>\n",
       "      <td>2020</td>\n",
       "      <td>iPhone_12</td>\n",
       "      <td>91</td>\n",
       "      <td>256</td>\n",
       "      <td>yes</td>\n",
       "      <td>kijiji</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>969</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1326.000000</td>\n",
       "      <td>2022</td>\n",
       "      <td>iPhone_14</td>\n",
       "      <td>91</td>\n",
       "      <td>64</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>1394</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>458.000000</td>\n",
       "      <td>2019</td>\n",
       "      <td>iPhone_11</td>\n",
       "      <td>75</td>\n",
       "      <td>256</td>\n",
       "      <td>no</td>\n",
       "      <td>facebook</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>702</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>487.000000</td>\n",
       "      <td>2019</td>\n",
       "      <td>iPhone_11</td>\n",
       "      <td>87</td>\n",
       "      <td>256</td>\n",
       "      <td>no</td>\n",
       "      <td>facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>no</td>\n",
       "      <td>781</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1340.000000</td>\n",
       "      <td>2022</td>\n",
       "      <td>iPhone_14</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>yes</td>\n",
       "      <td>craigslist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>1411</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1144.000000</td>\n",
       "      <td>2021</td>\n",
       "      <td>iPhone_13</td>\n",
       "      <td>94</td>\n",
       "      <td>128</td>\n",
       "      <td>yes</td>\n",
       "      <td>facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>1249</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           price  year_made       name  battery_life_percentage  storage  \\\n",
       "0     551.000000       2019  iPhone_11                       74       64   \n",
       "1     822.000000       2020  iPhone_12                       94      128   \n",
       "2    1008.000000       2022  iPhone_14                       97      256   \n",
       "3    1013.164557       2021  iPhone_13                       90      128   \n",
       "4     839.000000       2020  iPhone_12                       91      256   \n",
       "..           ...        ...        ...                      ...      ...   \n",
       "344  1326.000000       2022  iPhone_14                       91       64   \n",
       "345   458.000000       2019  iPhone_11                       75      256   \n",
       "346   487.000000       2019  iPhone_11                       87      256   \n",
       "347  1340.000000       2022  iPhone_14                      100      256   \n",
       "348  1144.000000       2021  iPhone_13                       94      128   \n",
       "\n",
       "    magnet_charging marketplace  years_owned  visible_scratches  pro  \\\n",
       "0                no      kijiji            2                  9   no   \n",
       "1               yes  craigslist            2                  6   no   \n",
       "2               yes  craigslist            0                  2   no   \n",
       "3               yes  craigslist            2                  2   no   \n",
       "4               yes      kijiji            1                  5   no   \n",
       "..              ...         ...          ...                ...  ...   \n",
       "344             yes  craigslist            0                  0   no   \n",
       "345              no    facebook            3                  3   no   \n",
       "346              no    facebook            1                  7   no   \n",
       "347             yes  craigslist            0                  0   no   \n",
       "348             yes    facebook            1                  1  yes   \n",
       "\n",
       "     original_sale_price  #_of_previous_owners  megapixel  \n",
       "0                    747                     1         12  \n",
       "1                    888                     1         16  \n",
       "2                   1185                     1         22  \n",
       "3                    887                     1         20  \n",
       "4                    969                     1         16  \n",
       "..                   ...                   ...        ...  \n",
       "344                 1394                     1         22  \n",
       "345                  702                     2         12  \n",
       "346                  781                     2         12  \n",
       "347                 1411                     1         22  \n",
       "348                 1249                     1         20  \n",
       "\n",
       "[349 rows x 13 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: Using np.where with the loc function for phone averages\n",
    "df_phone['price'] = np.where(np.isnan(df_phone['price']), phone_avg.loc[df_phone['name']], df_phone['price'])\n",
    "df_phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price                      0\n",
       "year_made                  0\n",
       "name                       0\n",
       "battery_life_percentage    0\n",
       "storage                    0\n",
       "magnet_charging            0\n",
       "marketplace                0\n",
       "years_owned                0\n",
       "visible_scratches          0\n",
       "pro                        0\n",
       "original_sale_price        0\n",
       "#_of_previous_owners       0\n",
       "megapixel                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see if anymore null values are left\n",
    "df_phone.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
